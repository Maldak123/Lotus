<img src="./Banner.webp" alt="" />

# üå∏ Lotus ‚Äî Chatbot Inteligente Baseado em RAG

Lotus √© uma aplica√ß√£o de **chatbot inteligente** baseada em **RAG (Retrieval‚ÄëAugmented Generation)**. O sistema permite que utilizadores fa√ßam upload de documentos, processem o seu conte√∫do e conversem com uma Intelig√™ncia Artificial que utiliza esses arquivos como **contexto** para responder a perguntas de forma mais precisa e confi√°vel.

---

## üìÇ Estrutura do Projeto

```text
Lotus/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/          # Rotas da API (Chat, Files)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/         # Configura√ß√µes, Logging, Prompts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ domain/       # Modelos de Dom√≠nio (DTOs)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/      # Schemas Pydantic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/     # L√≥gica de Neg√≥cio (RAG, Redis, Pinecone)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/        # Validadores e Utilit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ .env
‚îÇ
‚îî‚îÄ‚îÄ frontend/
    ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îú‚îÄ‚îÄ components/   # Componentes React (Chat, Sidebar, Inputs)
    ‚îÇ   ‚îú‚îÄ‚îÄ contexts/     # Context API (Chat, Files)
    ‚îÇ   ‚îú‚îÄ‚îÄ services/     # Integra√ß√£o com API (Fetch)
    ‚îÇ   ‚îú‚îÄ‚îÄ types/        # Defini√ß√µes TypeScript
    ‚îÇ   ‚îî‚îÄ‚îÄ layout/       # Estrutura de Header / Page
    ‚îî‚îÄ‚îÄ package.json
```
---

## ‚ú® Funcionalidades Principais

* **Upload de Arquivos**

  * Suporte para m√∫ltiplos formatos de arquivos.

* **Processamento RAG (Retrieval‚ÄëAugmented Generation)**

  * **Embeddings:** Os arquivos enviados s√£o processados e convertidos em vetores (embeddings) utilizando **Voyage AI (MongoDB)**.
  * **LLM (Large Language Model):** O modelo **`gemini-2.5-flash`** (Google Gemini) recebe o contexto recuperado e gera as respostas.

---

## üèóÔ∏è Arquitetura do Sistema

O fluxo de dados ocorre da seguinte forma:

### üìä Diagrama de Arquitetura

```mermaid
flowchart TB
 subgraph Frontend["Frontend (React + Vite)"]
        UI["Interface UI"]
        ChatComp["Componente Chat"]
        FileComp["Gestor de arquivos"]
        ChatService["ChatService.ts"]
        FileService["FileService.ts"]
  end

 subgraph Controllers["Controllers"]
        ChatCtrl["Chat Endpoint"]
        FileCtrl["File Endpoint"]
  end

 subgraph Services["Services"]
        Guard["Guardrail Service"]
        Process["Process File Service"]
        EmbedService["Embeddings Service"]
        PineconeService["Pinecone Service"]
  end

 subgraph Backend["Backend (Python / FastAPI)"]
        API["API Gateway / main.py"]
        Controllers
        Services
        Worker["Worker.py / Background Task"]
  end

 subgraph Infrastructure["Infraestrutura & Servi√ßos Externos"]
        Redis[("Redis - Queue / Cache")]
        Pinecone[("Pinecone - Vector DB")]
        LLM["Google Gemini API"]
  end

    User(("Usu√°rio")) -- Envia mensagem --> UI
    UI --> ChatComp & FileComp
    ChatComp --> ChatService
    ChatService -- POST /chat --> API
    API --> ChatCtrl
    ChatCtrl -- 1. Valida√ß√£o --> Guard
    ChatCtrl -- 2. Embedding da Pergunta --> EmbedService
    ChatCtrl -- 3. Busca de Contexto --> PineconeService
    PineconeService <-- Query Vectors --> Pinecone
    ChatCtrl -- 4. Prompt + Contexto --> LLM
    LLM -- Resposta --> ChatCtrl
    ChatCtrl -- Resposta Final --> ChatService

    User -- Upload de Arquivo --> UI
    FileComp --> FileService
    FileService -- POST /files --> API
    API --> FileCtrl
    FileCtrl -- Enfileirar Tarefa --> Redis
    Redis -- Consumir Tarefa --> Worker
    Worker -- Ler e Processar --> Process
    Process -- Gerar Embeddings --> EmbedService
    EmbedService -- Upsert --> PineconeService
    PineconeService -- Persistir --> Pinecone
```

---

## üß© Componentes da Arquitetura

### Backend

* **Framework:** FastAPI (Python 3.12+)
* **Responsabilidades:**

  * Orquestra√ß√£o da l√≥gica de neg√≥cio
  * Processamento de arquivos
  * Integra√ß√£o com servi√ßos de embeddings, base vetorial e LLM

### Frontend

* **Framework:** React + Vite
* **Responsabilidades:**

  * Interface de utilizador
  * Upload de arquivos
  * Chat em tempo real com a IA

---

## üöÄ Tecnologias Utilizadas

### Backend (`/backend`)

* **Linguagem:** Python 3.12+
* **Framework Web:** FastAPI
* **IA & LLM:**

  * LangChain (orquestra√ß√£o de cadeias de IA)
  * Google Gemini (`gemini-2.5-flash`)
  * Voyage AI (embeddings)
* **Base de Dados:**

  * Pinecone ‚Äî base de dados vetorial
  * Redis ‚Äî cache e hist√≥rico de chat
* **Seguran√ßa:** Guardrails para valida√ß√£o de input seguro

### Frontend (`/frontend`)

* **Framework:** React 19
* **Build Tool:** Vite
* **Linguagem:** TypeScript
* **Estiliza√ß√£o:** Tailwind CSS v4
* **Componentes:**

  * Lucide React (√≠cones)
  * React Markdown (renderiza√ß√£o de texto)

---

## üì¶ Instala√ß√£o e Execu√ß√£o

### üõ†Ô∏è Pr√©-requisitos

Para rodar o projeto localmente, ir√° precisar de:

* Python 3.12+
* Node.js 20+
* Docker & Docker Compose (opcional, mas recomendado para o Redis)
* Contas e chaves de API para:

  * Google AI Studio (Gemini)
  * Pinecone
  * Voyage AI
  * Redis (local ou cloud)

---

### ‚ñ∂Ô∏è Passos de Instala√ß√£o

#### 1Ô∏è‚É£ Clonar o Reposit√≥rio

```bash
git clone https://github.com/Maldak123/Lotus.git
cd Lotus
```

---

#### 2Ô∏è‚É£ Configurar o Backend

```bash
cd backend
```

##### Criar e ativar o ambiente virtual

**Linux / macOS**

```bash
python -m venv venv
source venv/bin/activate
```

**Windows**

```powershell
python -m venv venv
.\venv\Scripts\activate
```

##### Instalar depend√™ncias

```bash
pip install -r requirements.txt
```

##### Configurar vari√°veis de ambiente

Crie um ficheiro `.env` em `backend/`:

```env
# Redis Configuration
REDIS_HOST_NAME=localhost
REDIS_PASSWORD=sua_senha_redis
REDIS_PORT=6379
REDIS_CHAT_URL=redis://:sua_senha_redis@localhost:6379/0

# AI Services Keys
GOOGLE_API_KEY=sua_chave_google_gemini
VOYAGE_API_KEY=sua_chave_voyage
PINECONE_API_KEY=sua_chave_pinecone

# Pinecone Config
PINECONE_HOST_NAME=seu_host_pinecone
PINECONE_INDEX_NAME=nome_do_index
```

##### Iniciar o servidor

```bash
uvicorn main:app --reload
```

* Backend dispon√≠vel em: **[http://localhost:8000](http://localhost:8000)**
* Documenta√ß√£o da API: **/docs**

#### Iniciar o Worker na ra√≠z do Backend

```bash
python3 worker.py
```

---

#### 3Ô∏è‚É£ Configurar e Iniciar o Frontend

```bash
cd ../frontend
```

##### Instalar depend√™ncias

```bash
npm install
# ou yarn install
```

##### Iniciar o servidor de desenvolvimento

```bash
npm run dev
# ou yarn dev
```

---


## üìÑ Licen√ßa

Este projeto foi feito apenas como forma de estudo, e est√° licenciado sob a **MIT License**.
